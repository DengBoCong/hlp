{
  "seq2seq": {
    "vocab_size": 300,
    "embedding_dim": 256,
    "units": 1024,
    "max_train_data_size": 36,
    "max_length": 40
  },
  "transformer": {
    "num_layers": 2,
    "d_model": 256,
    "num_heads": 8,
    "units": 512,
    "dropout": 0.1,
    "vocab_size": 300,
    "embedding_dim": 256,
    "max_train_data_size": 36,
    "max_length": 40
  },
  "smn": {
    "embedding_dim": 200,
    "max_sentence": 50,
    "max_utterance": 10,
    "units": 200,
    "vocab_size": 2000,
    "max_train_data_size": 36,
    "learning_rate": 0.001,
    "max_valid_data_size": 100,
    "max_database_size": 1700
  },
  "seq2seq_dict_fn": "tensorflow_src\\data\\seq2seq_dict.json",
  "seq2seq_checkpoint": "tensorflow_src\\checkpoint\\seq2seq",
  "transformer_dict_fn": "tensorflow_src\\data\\transformer_dict.json",
  "transformer_checkpoint": "tensorflow_src\\checkpoint\\transformer",
  "smn_dict_fn": "tensorflow_src\\data\\smn_dict_fn",
  "smn_checkpoint": "tensorflow_src\\checkpoint\\smn",
  "resource_data": "data\\train.txt",
  "tokenized_data": "tensorflow_src\\data\\train_tokenized.txt",
  "lccc_data": "data\\LCCC.json",
  "lccc_tokenized_data": "tensorflow_src\\data\\lccc_tokenized.txt",
  "douban_tokenized_data": "data\\douban.txt",
  "ubuntu_tokenized_data": "data\\ubuntu_train.txt",
  "ubuntu_valid_data": "data\\ubuntu_valid.txt",
  "candidate_database": "tensorflow_src\\data\\candidate.json",
  "batch_size": 32,
  "buffer_size": 20000,
  "beam_size": 3,
  "epochs": 1,
  "start_sign": "start",
  "end_sign": "end"
}